{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "import mysql.connector as msql\n",
    "from mysql.connector import Error\n",
    "from geopy.geocoders import Nominatim \n",
    "geolocator = Nominatim(user_agent=\"MakroAnalyse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduzca la dirección donde se encuentren los conjuntos de datos: \n"
     ]
    }
   ],
   "source": [
    "print('Introduzca la dirección donde se encuentren los conjuntos de datos: ')\n",
    "\n",
    "direccion = input()\n",
    "carpeta_datos = direccion + '\\\\'\n",
    "lista_datos = []\n",
    "for file in os.listdir(carpeta_datos):\n",
    "    if file.endswith('.csv'):\n",
    "        lista_datos.append(file)\n",
    "    if file.endswith('.json'):\n",
    "        lista_datos.append(file)\n",
    "lista_datos = sorted(lista_datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta1 = (carpeta_datos + 'product_category_name_translation.csv')\n",
    "ruta2 = (carpeta_datos + 'olist_closed_deals_dataset.csv')\n",
    "ruta3 = (carpeta_datos + 'geolocation_dataset_brazil.csv')\n",
    "ruta4 = (carpeta_datos + 'olist_products_dataset.csv')\n",
    "ruta5 = (carpeta_datos + 'olist_order_payments_dataset.csv')\n",
    "ruta6 = (carpeta_datos +  'olist_orders_dataset.csv')\n",
    "ruta7 = (carpeta_datos + 'olist_order_reviews_dataset.csv')\n",
    "ruta8 = (carpeta_datos + 'olist_order_items_dataset.csv')\n",
    "ruta9 = (carpeta_datos + 'olist_sellers_dataset.csv')\n",
    "ruta10 = (carpeta_datos + 'olist_customers_dataset.csv')\n",
    "rutaestados = (carpeta_datos + 'estados.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por favor, ingrese su usuario de MySQL\n",
      "Por favor, ingrese su contraseña de MySQL\n"
     ]
    }
   ],
   "source": [
    "print('Por favor, ingrese su usuario de MySQL: ')\n",
    "user = input()\n",
    "print('Por favor, ingrese su contraseña de MySQL: ')\n",
    "password = input()\n",
    "print('Por favor, ingrese el host de MySQL: ')\n",
    "host = input()\n",
    "database = 'db_olist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONEXIÓN AZURE\n",
    "# conn = msql.connect(host='olist-henrygrupo5.mysql.database.azure.com', user= 'mnp_henry_grupo5@olist-henrygrupo5',\n",
    "#                        password='Datascience22#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database is created\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = msql.connect(host= host, user = user,\n",
    "                        password = password)\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"CREATE DATABASE IF NOT EXISTS db_olist\")\n",
    "        print(\"Database is created\")\n",
    "except Error as e:\n",
    "    print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_categoryproduct(ruta1):\n",
    "\n",
    "    #Normalizacion\n",
    "    data_category_product = pd.read_csv(ruta1)\n",
    "    data_category_product.loc[71] = ['sin_categoria','NoCategory']\n",
    "    data_category_product.reset_index(inplace=True)\n",
    "    data_category_product.rename(columns={'index':'idproduct_name'}, inplace=True)\n",
    "\n",
    "\n",
    "    #Carga a SQL\n",
    "    try:\n",
    "        conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "        if conn.is_connected():\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"select database();\")\n",
    "            record = cursor.fetchone()\n",
    "            cursor.execute('DROP TABLE IF EXISTS category_product;')\n",
    "            cursor.execute(\"CREATE TABLE category_product(idproduct_name INT(11), product_category_name VARCHAR(255), product_category_name_english VARCHAR(255), PRIMARY KEY (idproduct_name))\")\n",
    "            for i,row in data_category_product.iterrows():\n",
    "\n",
    "#OJOTAAAA QUE ACÀ HAY QUE CAMBIAR EL NOMBRE DE LA BASE DE DATOS CADA VEZ QUE HAGO UN INSERT EN TODAS LAS FUNCIONES\n",
    "                sql = \"INSERT INTO category_product VALUES (%s, %s, %s)\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "\n",
    "                conn.commit()\n",
    "\n",
    "    except Error as e:\n",
    "                print(\"Error de conexión con MySQL\", e)\n",
    "\n",
    "    return data_category_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_closed(ruta2):\n",
    "    print('normalizando')\n",
    "    data_closed = pd.read_csv(ruta2)\n",
    "    data_closed['won_date'] = pd.to_datetime(data_closed['won_date'])\n",
    "    data_closed.drop(columns=['declared_monthly_revenue', 'sr_id', 'sdr_id', 'lead_behaviour_profile', \\\n",
    "        'has_company','lead_type','has_gtin','business_type' ,'average_stock', 'declared_product_catalog_size'], inplace=True)\n",
    "    data_closed.reset_index(inplace=True)\n",
    "    data_closed.rename(columns={'index':'closed_id'}, inplace=True)\n",
    "    data_closed.dropna(inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    try:\n",
    "        conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "        if conn.is_connected():\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"select database();\")\n",
    "            \n",
    "            record = cursor.fetchone()\n",
    "            cursor.execute('DROP TABLE IF EXISTS closed_deals;')\n",
    "           \n",
    "            cursor.execute(\"CREATE TABLE closed_deals(closed_id INT(11), mql_id VARCHAR(255), seller_id VARCHAR(255), won_date DATETIME(0), business_segment VARCHAR(50), PRIMARY KEY (closed_id))\")\n",
    "            for i,row in data_closed.iterrows():\n",
    "                #here %S means string values\n",
    "                # Habria que chequear aca si funciona con los Ints o los Floats o Fechas,inclusive. Siempre creo que se usa el %s.\n",
    "                sql = \"INSERT INTO closed_deals VALUES (%s,%s,%s,%s,%s)\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "                # the connection is not auto committed by default, so we must commit to save our changes\n",
    "                conn.commit()\n",
    "            \n",
    "\n",
    "\n",
    "    except Error as e:\n",
    "                print(\"Error de conexión con MySQL\", e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_geolocalizacion(ruta3, rutaestados):\n",
    "    geo = pd.read_csv(ruta3)\n",
    "    geo.drop_duplicates(inplace=True)\n",
    "    geo = geo.rename(columns={'geolocation_zip_code_prefix': 'zip_code', 'geolocation_lat':'geolatitud', \\\n",
    "        'geolocation_lng':'geolongitud', 'geolocation_city':'city', 'geolocation_state' : 'state'})\n",
    "    dfj = pd.read_json(rutaestados)\n",
    "    #Mergeamos ambas tablas\n",
    "    geo = geo.merge(dfj[['nome', 'sigla']], right_on='sigla', left_on='state')\n",
    "\n",
    "    #Renombramos columnas para unificar descripcion de mismo contenido de columna\n",
    "    geo.rename(columns={'nome':'state_name'}, inplace=True)\n",
    "\n",
    "    #Normalizamos mayúsculas\n",
    "    geo['city'] = geo['city'].str.title()\n",
    "\n",
    "    #Eliminamos duplicados por 'zip_code' \n",
    "    geo = geo.drop_duplicates('zip_code')\n",
    "\n",
    "    #Reseteamos indice\n",
    "    geo = geo.reset_index(drop=True)\n",
    "\n",
    "    #Finalmente, nos quedamos con las columnas que nos servirán a futuro.\n",
    "    geo = geo[['zip_code', 'geolatitud', 'geolongitud', 'city', 'state_name']]\n",
    "\n",
    "    #Reemplazamos aquellas latitudes y longitudes que estén en positivo\n",
    "\n",
    "    geo.loc[geo.geolongitud > 0, 'geolongitud'] = geo.geolongitud * (-1)\n",
    "    geo.loc[geo.geolatitud > 5, 'geolatitud'] = geo.geolatitud * (-1)\n",
    "\n",
    "\n",
    "    #'CREAMOS MÁSCARA DONDE SE CUMPLEN LAS 3 CONDICIONES'\n",
    "    a = (geo.geolongitud < -73) | (geo.geolongitud > -34) | (geo.geolatitud < -33)\n",
    "\n",
    "    #'Para buscar las coordenadas con más precisión'\n",
    "    geo['full_data'] = geo.state_name + ',' + geo.city \n",
    "\n",
    "    #'Traemos las coordenadas con Geopy donde se cumple la máscara'\n",
    "\n",
    "    geo.loc[a, 'gcode'] = geo[a]['full_data'].apply(geolocator.geocode)\n",
    "    geo.loc[a,'lat'] = [g.latitude for g in geo[a]['gcode']]\n",
    "    geo.loc[a,'long'] = [g.longitude for g in geo[a]['gcode']]\n",
    "    \n",
    "    #'Reemplazamos en columna original'\n",
    "\n",
    "    geo.loc[a, 'geolatitud'] = geo[a]['lat']\n",
    "    geo.loc[a, 'geolongitud'] = geo[a]['long']\n",
    "    \n",
    "    # Eliminamos columnas auxiliares\n",
    "    geo.drop(columns= ['gcode', 'lat', 'long', 'full_data'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    geo['zip_code'] = geo['zip_code'].astype(str)\n",
    "\n",
    "    try:\n",
    "        conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "        if conn.is_connected():\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"select database();\")\n",
    "            record = cursor.fetchone()\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS geolocation;\")\n",
    "            cursor.execute(\"CREATE TABLE geolocation (zip_code INT(11), geolatitud DECIMAL(13,10), geolongitud DECIMAL(13,10), city VARCHAR (255), state_name VARCHAR (255), PRIMARY KEY (zip_code))\")\n",
    "            \n",
    "                \n",
    "            for i,row in geo.iterrows():\n",
    "                #here %S means string values\n",
    "                # Habria que chequear aca si funciona con los Ints o los Floats o Fechas,inclusive. Siempre creo que se usa el %s.\n",
    "                sql = \"INSERT INTO geolocation VALUES (%s,%s,%s,%s,%s)\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "                # the connection is not auto committed by default, so we must commit to save our changes\n",
    "                conn.commit()\n",
    "\n",
    "    except Error as e:\n",
    "                print(\"Error de conexión con MySQL\", e)\n",
    "\n",
    "    return geo\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_product(ruta4):\n",
    "    data_products = pd.read_csv(ruta4)\n",
    "    data_products.drop(columns=['product_name_lenght', 'product_description_lenght'], axis=1, inplace=True)\n",
    "    ## UTILIZAR FUNCION DE ETL_CATEGORYPRODUCT\n",
    "    datamerge = merge1\n",
    "    data_products.drop(columns=['product_photos_qty'], inplace=True)\n",
    "    data_products['product_category_name'] = data_products['product_category_name'].fillna('sin_categoria')\n",
    "    data_products = pd.merge(datamerge,data_products)\n",
    "    data_products.drop(columns='product_category_name', inplace=True)\n",
    "    data_products.drop(columns='idproduct_name', inplace= True)\n",
    "\n",
    "    #Utilizamos la media para rellenar espacios nulos\n",
    "    product_weight_median = data_products['product_weight_g'].median()\n",
    "    product_length_median = data_products['product_length_cm'].median()\n",
    "    product_height_median = data_products['product_height_cm'].median()\n",
    "    product_width_median = data_products['product_width_cm'].median()\n",
    "    data_products['product_weight_g'].fillna(product_weight_median, inplace=True)\n",
    "    data_products['product_length_cm'].fillna(product_length_median, inplace=True)\n",
    "    data_products['product_height_cm'].fillna(product_height_median, inplace=True)\n",
    "    data_products['product_width_cm'].fillna(product_width_median, inplace=True)    \n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "        if conn.is_connected():\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"select database();\")\n",
    "            record = cursor.fetchone()\n",
    "            cursor.execute('DROP TABLE IF EXISTS product;')\n",
    "            cursor.execute(\"CREATE TABLE product (product_category_name_english varchar(255),product_id varchar(255), product_weight_g FLOAT(10), product_length_cm FLOAT(10), product_height_cm FLOAT(10), product_width_cm FLOAT(10), PRIMARY KEY (product_id))\")\n",
    "            for i,row in data_products.iterrows():\n",
    "                sql = \"INSERT INTO product VALUES (%s,%s,%s,%s,%s,%s)\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "                conn.commit()\n",
    "\n",
    "\n",
    "    except Error as e:\n",
    "                print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_payment(ruta5):\n",
    "    data_payment = pd.read_csv(ruta5)\n",
    "    data_payment['payment_type'] = data_payment['payment_type'].replace('boleto', 'voucher')\n",
    "\n",
    "    data_payment.reset_index(inplace=True)\n",
    "    data_payment.rename(columns={'index':'payment_id'}, inplace=True)\n",
    "    data_payment['payment_id'] = data_payment['payment_id'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "        if conn.is_connected():\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"select database();\")\n",
    "            record = cursor.fetchone()\n",
    "            cursor.execute('DROP TABLE IF EXISTS payment;')\n",
    "            cursor.execute(\"CREATE TABLE payment(payment_id INT(11), order_id varchar(255),payment_sequential INT(5), payment_type VARCHAR(50), payment_installments INT(5), payment_value FLOAT(12), PRIMARY KEY(payment_id))\")\n",
    "            for i,row in data_payment.iterrows():\n",
    "                sql = \"INSERT INTO payment VALUES (%s,%s,%s,%s,%s,%s)\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "                conn.commit()\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "    except Error as e:\n",
    "                print(\"Error while connecting to MySQL\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_order(ruta6):\n",
    "    data_order = pd.read_csv(ruta6)\n",
    "    date_cols = ['order_purchase_timestamp','order_approved_at','order_delivered_carrier_date','order_delivered_customer_date','order_estimated_delivery_date']\n",
    "\n",
    "    for j in date_cols:\n",
    "        data_order[j] = pd.to_datetime(data_order[j])\n",
    "    data_order.drop([47552], inplace= True)\n",
    "    diferencia_compra_aprobacion = data_order['order_approved_at'] - data_order['order_purchase_timestamp']\n",
    "    diferencia_aprobacion_envio = data_order['order_delivered_carrier_date'] - data_order['order_approved_at']\n",
    "\n",
    "    Q1 = diferencia_compra_aprobacion.dt.days.quantile(0.25) \n",
    "    Q3 = diferencia_compra_aprobacion.dt.days.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    BI = Q1 - 1.5*IQR\n",
    "    BS = Q3 + 1.5*IQR\n",
    "    out = (diferencia_compra_aprobacion.dt.days<BI) | (diferencia_compra_aprobacion.dt.days>BS)\n",
    "\n",
    "    promedio_demora_aprobacion = diferencia_compra_aprobacion[~out].mean()\n",
    "\n",
    "    data_order.loc[diferencia_aprobacion_envio.dt.days < 0, 'order_approved_at'] = data_order.order_purchase_timestamp + pd.Timedelta(promedio_demora_aprobacion) \n",
    "\n",
    "    diferencia_aprobacion_envio_2 = data_order['order_delivered_carrier_date'] - data_order['order_approved_at']\n",
    "\n",
    "    Q1 = diferencia_aprobacion_envio_2.dt.days.quantile(0.25) \n",
    "    Q3 = diferencia_aprobacion_envio_2.dt.days.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    BI = Q1 - 1.5*IQR\n",
    "    BS = Q3 + 1.5*IQR\n",
    "    out = (diferencia_aprobacion_envio_2.dt.days<BI) | (diferencia_aprobacion_envio_2.dt.days>BS)\n",
    "\n",
    "    promedio_demora_salida = diferencia_aprobacion_envio_2[~out].mean()\n",
    "\n",
    "    data_order.loc[diferencia_aprobacion_envio_2.dt.days < 0, 'order_delivered_carrier_date'] = data_order.order_approved_at + pd.Timedelta(promedio_demora_salida) \n",
    "\n",
    "    diferencia_salida_llegada = data_order['order_delivered_customer_date'] - data_order['order_delivered_carrier_date']\n",
    "\n",
    "    Q1 = diferencia_salida_llegada.dt.days.quantile(0.25) \n",
    "    Q3 = diferencia_salida_llegada.dt.days.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    BI = Q1 - 1.5*IQR\n",
    "    BS = Q3 + 1.5*IQR\n",
    "    out = (diferencia_salida_llegada.dt.days<BI) | (diferencia_salida_llegada.dt.days>BS)\n",
    "\n",
    "    promedio_demora_llegada = diferencia_salida_llegada[~out].mean()\n",
    "\n",
    "    data_order.loc[diferencia_salida_llegada.dt.days < 0, 'order_delivered_customer_date'] = data_order.order_delivered_carrier_date + pd.Timedelta(promedio_demora_llegada) \n",
    "    \n",
    "    data_order.loc[(data_order.order_status == 'delivered') & (data_order.order_approved_at.isnull()), 'order_approved_at'] = data_order.order_purchase_timestamp + pd.Timedelta(promedio_demora_aprobacion) \n",
    "\n",
    "    data_order.loc[(data_order.order_status == 'delivered') & (data_order.order_delivered_carrier_date.isnull()), 'order_delivered_carrier_date'] = data_order.order_approved_at + pd.Timedelta(promedio_demora_salida) \n",
    "\n",
    "    data_order.loc[(data_order.order_status == 'delivered') & (data_order.order_delivered_customer_date.isnull()), 'order_delivered_customer_date'] = data_order.order_delivered_carrier_date + pd.Timedelta(promedio_demora_llegada) \n",
    "\n",
    "    lista = ['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "\n",
    "    for i in lista:\n",
    "        data_order[i] = pd.to_datetime(data_order[i]).round('s')\n",
    "\n",
    "    data_order.replace({np.nan: None}, inplace= True)\n",
    "\n",
    "    try:\n",
    "        conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "        if conn.is_connected():\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"select database();\")\n",
    "            record = cursor.fetchone()\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS table_order;\")\n",
    "            cursor.execute(\"CREATE TABLE table_order (order_id VARCHAR (255), customer_id VARCHAR (255), order_status VARCHAR (255), order_purchase_timestamp DATETIME(0),\\\n",
    "                order_approved_at DATETIME(0), order_delivered_carrier_date DATETIME(0), order_delivered_customer_date DATETIME(0),\\\n",
    "                    order_estimated_delivery_date DATETIME(0), PRIMARY KEY (order_id))\")\n",
    "            \n",
    "            for i,row in data_order.iterrows():\n",
    "                #here %S means string values\n",
    "                # Habria que chequear aca si funciona con los Ints o los Floats o Fechas,inclusive. Siempre creo que se usa el %s.\n",
    "                sql = \"INSERT INTO table_order VALUES (%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "                # the connection is not auto committed by default, so we must commit to save our changes\n",
    "                conn.commit()\n",
    "\n",
    "\n",
    "\n",
    "    except Error as e:\n",
    "                print(\"Error while connecting to MySQL\", e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_review(ruta7):\n",
    "    data_order_review = pd.read_csv(ruta7)\n",
    "    data_order_review['review_creation_date'] = pd.to_datetime(data_order_review['review_creation_date'])\n",
    "    data_order_review['review_id'] = data_order_review.index\n",
    "    data_order_review['review_id'] = data_order_review['review_id'].astype(str)\n",
    "    data_order_review.drop(columns=['review_comment_title', 'review_comment_message', 'review_answer_timestamp'], inplace=True)\n",
    "\n",
    "\n",
    "    try:\n",
    "        conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "        if conn.is_connected():\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"select database();\")\n",
    "            record = cursor.fetchone()\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS review;\")\n",
    "            cursor.execute(\"CREATE TABLE review (review_id INT(10), order_id VARCHAR (255), review_score INT(10), review_creation_date DATE, PRIMARY KEY (review_id))\")\n",
    "                \n",
    "\n",
    "            for i,row in data_order_review.iterrows():\n",
    "                #here %S means string values\n",
    "                # Habria que chequear aca si funciona con los Ints o los Floats o Fechas,inclusive. Siempre creo que se usa el %s.\n",
    "                sql = \"INSERT INTO review VALUES (%s,%s,%s, %s)\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "                # the connection is not auto committed by default, so we must commit to save our changes\n",
    "                conn.commit()\n",
    "\n",
    "\n",
    "    except Error as e:\n",
    "                print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_items(ruta8):\n",
    "    data_order= pd.read_csv(ruta8)\n",
    "    data_order['shipping_limit_date'] = pd.to_datetime(data_order['shipping_limit_date'])\n",
    "    data_order['percentagePF'] = ( data_order['freight_value'] * 100 ) / data_order['price']\n",
    "    data_order.rename(columns= {'order_item_id' : 'quantity'}, inplace= True)\n",
    "    data_order = data_order.reindex(columns = ['order_id', 'product_id', 'seller_id', 'shipping_limit_date', 'quantity', 'price', 'freight_value', 'percentagePF'])\n",
    "    data_order.reset_index(inplace=True)\n",
    "    data_order.rename(columns={'index':'id_orderitem'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "        if conn.is_connected():\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"select database();\")\n",
    "            record = cursor.fetchone()\n",
    "            cursor.execute('DROP TABLE IF EXISTS order_items;')\n",
    "            cursor.execute(\"CREATE TABLE order_items(id_orderitem INT(11), order_id varchar(255),product_id varchar(255), seller_id varchar(255), shipping_limit_date DATETIME(0), quantity INT(5), price FLOAT(10), freight_value FLOAT(10), percentagePF FLOAT(10), PRIMARY KEY (id_orderitem))\")\n",
    "            for i,row in data_order.iterrows():\n",
    "                #here %S means string values\n",
    "                # Habria que chequear aca si funciona con los Ints o los Floats o Fechas,inclusive. Siempre creo que se usa el %s.\n",
    "                sql = \"INSERT INTO order_items VALUES (%s,%s,%s,%s,%s,%s,%s,%s, %s)\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "                # the connection is not auto committed by default, so we must commit to save our changes\n",
    "                conn.commit()\n",
    "\n",
    "    except Error as e:\n",
    "                print(\"Error while connecting to MySQL\", e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_seller(ruta9):\n",
    "    \n",
    "    df = pd.read_csv(ruta9)\n",
    "    df.rename(columns = {'seller_zip_code_prefix': 'zip_code', 'seller_city': 'city', 'seller_state': 'state'}, inplace= True)\n",
    "    df['city'] = df['city'].str.title()\n",
    "    df['zip_code'] = df['zip_code'].astype(str)\n",
    "    ## AGREGAR RUTA\n",
    "    #dfgeo = pd.read_parquet(r'C:\\Users\\leand\\Desktop\\Data Science (Henry)\\Proyectos\\Proyecto_grupal\\DS-Proyecto_Grupal_Olist\\data_parquet\\geolocation_cleanP')\n",
    "    dfgeo = merge_geo\n",
    "    df = df[['seller_id', 'zip_code']].merge(dfgeo[['zip_code', 'city', 'state_name']], on='zip_code')\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "        if conn.is_connected():\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"select database();\")\n",
    "            record = cursor.fetchone()\n",
    "            cursor.execute('DROP TABLE IF EXISTS seller;')\n",
    "            cursor.execute(\"CREATE TABLE seller(seller_id VARCHAR(255), zip_code INT(10), city VARCHAR(255), state_name VARCHAR(255), PRIMARY KEY(seller_id))\")\n",
    "            for i,row in df.iterrows():\n",
    "                #here %S means string values\n",
    "                # Habria que chequear aca si funciona con los Ints o los Floats o Fechas,inclusive. Siempre creo que se usa el %s.\n",
    "                sql = \"INSERT INTO seller VALUES (%s,%s,%s,%s)\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "                # the connection is not auto committed by default, so we must commit to save our changes\n",
    "                conn.commit()\n",
    "\n",
    "\n",
    "    except Error as e:\n",
    "                print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_customer(ruta10):\n",
    "    ##UTILIZA GEO\n",
    "    df = pd.read_csv(ruta10)\n",
    "    dfgeo = merge_geo\n",
    "    df.rename(columns = {'customer_zip_code_prefix': 'zip_code', 'customer_city': 'city', 'customer_state': 'state'}, inplace= True)\n",
    "    df['city'] = df['city'].str.title()\n",
    "    df.rename(columns={'customer_zip_code_prefix': 'zip_code'}, inplace=True)\n",
    "    df['zip_code'] = df['zip_code'].astype(str)\n",
    "    df = df[['customer_id', 'customer_unique_id', 'zip_code']].merge(dfgeo[['zip_code', 'city', 'state_name']], on='zip_code')\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "        if conn.is_connected():\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"select database();\")\n",
    "            record = cursor.fetchone()\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS customer;\")\n",
    "            cursor.execute(\"CREATE TABLE customer (customer_id VARCHAR (255), customer_unique_id VARCHAR (255), zip_code INT(10), city VARCHAR (255), state_name VARCHAR(255), PRIMARY KEY (customer_id))\")\n",
    "            \n",
    "            for i,row in df.iterrows():\n",
    "                #here %S means string values\n",
    "                # Habria que chequear aca si funciona con los Ints o los Floats o Fechas,inclusive. Siempre creo que se usa el %s.\n",
    "                sql = \"INSERT INTO customer VALUES (%s,%s,%s,%s,%s)\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "                # the connection is not auto committed by default, so we must commit to save our changes\n",
    "                conn.commit()\n",
    "\n",
    "\n",
    "    except Error as e:\n",
    "                print(\"Error while connecting to MySQL\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funciones = [etl_categoryproduct, etl_closed, etl_geolocalizacion, etl_product, etl_payment, etl_order, etl_review, etl_items, etl_seller, etl_customer]\n",
    "rutas = [ruta1, ruta2, ruta3, ruta4, ruta5, ruta6, ruta7, ruta8, ruta9, ruta10]\n",
    "j = 0\n",
    "p = 0\n",
    "\n",
    "for i in funciones:\n",
    "   print('Normalizando el archivo', rutas[j].split(carpeta_datos)[1], 'y cargando en base de datos...')\n",
    "   \n",
    "   if i == etl_geolocalizacion:\n",
    "      merge_geo = i(rutas[j], rutaestados)\n",
    "   elif i == etl_categoryproduct:\n",
    "      merge1 = i(rutas[j])\n",
    "   else:\n",
    "      i(rutas[j])\n",
    "\n",
    "   j = j + 1\n",
    "   p = p + 1\n",
    "   \n",
    "print('El proceso ETL ha finalizado exitosamente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        cursor.execute(\"ALTER TABLE category_product ADD INDEX(product_category_name_english);\")\n",
    "        cursor.execute(\"ALTER TABLE closed_deals ADD INDEX(seller_id);\")\n",
    "        cursor.execute(\"ALTER TABLE customer ADD INDEX(zip_code);\")\n",
    "        cursor.execute(\"ALTER TABLE order_items ADD INDEX(order_id);\")\n",
    "        cursor.execute(\"ALTER TABLE order_items ADD INDEX(product_id);\")\n",
    "        cursor.execute(\"ALTER TABLE order_items ADD INDEX(seller_id);\")\n",
    "        cursor.execute(\"ALTER TABLE payment ADD INDEX(order_id);\")\n",
    "        cursor.execute(\"ALTER TABLE product ADD INDEX(product_category_name_english);\")\n",
    "        cursor.execute(\"ALTER TABLE review ADD INDEX(order_id);\")\n",
    "        cursor.execute(\"ALTER TABLE seller ADD INDEX(zip_code);\")\n",
    "        cursor.execute(\"ALTER TABLE seller ADD INDEX(seller_id);\")\n",
    "        cursor.execute(\"ALTER TABLE table_order ADD INDEX(customer_id);\")\n",
    "        cursor.execute(\"ALTER TABLE table_order ADD INDEX(order_id);\")\n",
    "\n",
    "\n",
    "except Error as e:\n",
    "            print(\"Error while connecting to MySQL\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = msql.connect(host= host, database= database, user= user, password= password)\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        cursor.execute(\"SET FOREIGN_KEY_CHECKS = 0;\")\n",
    "        cursor.execute(\"ALTER TABLE category_product ADD CONSTRAINT category_product_fk_product FOREIGN KEY (product_category_name_english) REFERENCES product (product_category_name_english) ON DELETE RESTRICT ON UPDATE RESTRICT;\")\n",
    "        cursor.execute(\"ALTER TABLE closed_deals ADD CONSTRAINT closed_deals_fk_seller FOREIGN KEY (seller_id) REFERENCES seller (seller_id) ON DELETE RESTRICT ON UPDATE RESTRICT;\")\n",
    "        cursor.execute(\"ALTER TABLE customer ADD CONSTRAINT customer_fk_geolocation FOREIGN KEY (zip_code) REFERENCES geolocation (zip_code) ON DELETE RESTRICT ON UPDATE RESTRICT;\")\n",
    "        cursor.execute(\"ALTER TABLE order_items ADD CONSTRAINT order_items_fk_table_order FOREIGN KEY (order_id) REFERENCES table_order (order_id) ON DELETE RESTRICT ON UPDATE RESTRICT;\")\n",
    "        cursor.execute(\"ALTER TABLE order_items ADD CONSTRAINT order_items_fk_product FOREIGN KEY (product_id) REFERENCES product (product_id) ON DELETE RESTRICT ON UPDATE RESTRICT;\")\n",
    "        cursor.execute(\"ALTER TABLE order_items ADD CONSTRAINT order_items_fk_seller FOREIGN KEY (seller_id) REFERENCES seller (seller_id) ON DELETE RESTRICT ON UPDATE RESTRICT;\")\n",
    "        cursor.execute(\"ALTER TABLE payment ADD CONSTRAINT payment_fk_table_order FOREIGN KEY (order_id) REFERENCES table_order (order_id) ON DELETE RESTRICT ON UPDATE RESTRICT;\")\n",
    "        cursor.execute(\"ALTER TABLE product ADD CONSTRAINT product_fk_category_product FOREIGN KEY (product_category_name_english) REFERENCES category_product (product_category_name_english) ON DELETE RESTRICT ON UPDATE RESTRICT;\")\n",
    "        cursor.execute(\"ALTER TABLE review ADD CONSTRAINT review_fk_table_order FOREIGN KEY (order_id) REFERENCES table_order (order_id) ON DELETE RESTRICT ON UPDATE RESTRICT;\")\n",
    "        cursor.execute(\"ALTER TABLE seller ADD CONSTRAINT seller_fk_geolocation FOREIGN KEY (zip_code) REFERENCES geolocation (zip_code) ON DELETE RESTRICT ON UPDATE RESTRICT;\")\n",
    "        cursor.execute(\"ALTER TABLE table_order ADD CONSTRAINT table_order_fk_customer FOREIGN KEY (customer_id) REFERENCES customer (customer_id) ON DELETE RESTRICT ON UPDATE RESTRICT;\")\n",
    "\n",
    "\n",
    "except Error as e:\n",
    "            print(\"Error while connecting to MySQL\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b0261dadc93494a3555537365c322d83416c4a1ed03d5df7c77bc94b07686c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
